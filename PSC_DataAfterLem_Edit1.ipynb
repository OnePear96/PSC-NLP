{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import nltk.data\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class JSONObject:\n",
    "     def __init__(self, d):\n",
    "         self.__dict__ = d\n",
    "\n",
    "with open(\"articles_Accuracy.json\", \"r\") as read_file:\n",
    "    data = read_file.read()\n",
    "    obj = json.loads(data,object_hook=JSONObject)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopworddic = set(stopwords.words('french'))\n",
    "article=['a','au','aux','un','une','le','la','les','de','des','ce','cet','cette','ces','son','sa','ses','leur','leurs','mon','ma','mes','ton','ta','tes','notre','notres','votre','votres']\n",
    "pronom=['je','tu','il','elle','nous','vous','ils','elles','on','y','en','se']\n",
    "coordination=['mais','ou','et','donc','or','ni','car']\n",
    "v=['aller','vais','vas','va','allez','allions','vont']\n",
    "stopworddic.update(set(article),set(pronom),set(coordination),set(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = FrenchLefffLemmatizer()\n",
    "def lemma(word):\n",
    "    a=lemmatizer.lemmatize(word,'all')\n",
    "    b=[x[1] for x in a]\n",
    "    if 'nc' in b:\n",
    "        return lemmatizer.lemmatize(word,'n')\n",
    "    if 'v' in b:\n",
    "        return lemmatizer.lemmatize(word,'v')\n",
    "    return lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "rawtokens=nltk.word_tokenize(obj[0].body_fr)\n",
    "metokens = [w.lower() for w in rawtokens if re.search('[a-zA-ZàâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]+',w)]\n",
    "latokens=[]\n",
    "for str in metokens:\n",
    "    if(re.search(r'\\w+\\'',str)):\n",
    "        str=re.sub(r'\\w+\\'', '', str) \n",
    "    latokens.append(str)\n",
    "tokens = [w for w in latokens if w not in stopworddic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_data=[]\n",
    "for doc in obj :\n",
    "    if len(doc.body_fr)>2 :\n",
    "        text=doc.body_fr\n",
    "        text=nltk.word_tokenize(text)\n",
    "        text = [w.lower() for w in text if re.search('[a-zA-ZàâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]+',w)]\n",
    "        latokens=[]\n",
    "        for str in text:\n",
    "            if(re.search(r'\\w+\\'',str)):\n",
    "                str=re.sub(r'\\w+\\'', '', str) \n",
    "            latokens.append(str)\n",
    "        tokens = [w for w in latokens if w not in stopworddic]\n",
    "        text = [lemma(w) for w in tokens]\n",
    "        tokenized_data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['groupe', 'défense', 'vouloir', 'accompagner', 'jeune', 'pousse', 'français', 'haut', 'potentiel', 'ici', 'banque', 'compléter', 'offre', 'travailler', 'insérer', 'écosystème', 'développement', 'entreprise', 'société', 'général', 'mettre', 'quête', 'nouveau', 'pépite', 'banque', 'défense', 'servir', 'déjà', 'start-up', 'dont', 'juger', 'particulièrement', 'prometteuses', 'annoncer', 'mardi', 'souhaiter', 'séduire', 'supplémentaires', 'horizon', 'ensemble', 'territoire', 'jargon', 'banque', 'pépite', 'entreprise', 'déjà', 'réussir', 'première', 'levée', 'fond', 'moins', 'euro', 'accompagner', 'incubateur', 'phare', 'fond', 'capital-risque', 'créer', 'idéalement', 'entrepreneur', 'coup', 'essai', 'pouvoir', 'agir', 'entreprise', 'déjà', 'suivre', 'banque', 'doit', 'encore', 'grandir', 'comme', 'recrutement', 'externe', 'parvenir', 'banque', 'peaufiner', 'arsenal', 'signer', 'lundi', 'prochain', 'partenariat', 'bpifrance', 'vue', 'notamment', 'faire', 'dialoguer', 'conseiller', 'réseau', 'bancaire', 'chargé', 'affaire', 'innovation', 'établissement', 'public', 'seul', 'bnp', 'paribas', 'heure', 'passé', 'tel', 'accord', 'bpifrance', 'deuxième', 'nouveauté', 'concerner', 'ensemble', 'jeune', 'pousse', 'tech', 'bénéficier', 'offre', 'dédier', 'baptisé', 'welcome', 'pack', 'startup', 'dernier', 'comprendre', 'notamment', 'service', 'banque', 'mobile', 'moyens', 'paiement', 'encore', 'bilan', 'patrimonial', 'industrialiser', 'pratique', 'démarche', 'groupe', 'bancaire', 'plus', 'loin', 'simple', 'offre', 'commercial', 'viser', 'désormais', 'industrialiser', 'pratique', 'déjà', 'place', 'depuis', 'plusieurs', 'année', 'animation', 'clientèle', 'si', 'particulière', 'compléter', 'entériner', 'dispositif', 'conseiller', 'référent', 'start-up', 'selon', 'ville', 'nombre', 'créateur', 'suivre', 'rôle', 'occuper', 'plein', 'temps', 'façon', 'partielle', 'conseiller', 'clientèle', 'classique', 'rôle', 'notamment', 'orienter', 'client', 'travers', 'ensemble', 'service', 'pouvoir', 'apporter', 'groupe', 'enfin', 'huit', 'ambassadeur', 'chargé', 'identifier', 'faire', 'connaître', 'direction', 'général', 'entreprise', 'portefeuille', 'plus', 'pointe', 'plus', 'prometteuses', 'travail', 'animation', 'interne', 'partage', 'client', 'aussi', 'marque', 'fabrique', 'banque', 'logo', 'rouge', 'noir', 'mener', 'passé', 'type', 'démarche', 'développer', 'service', 'banque', 'priver', 'travail', 'réseau', 'banque', 'mener', 'aussi', 'externe', 'devenir', 'partenaire', 'bancaire', 'vingtaine', 'incubateur', 'dont', 'station', 'f', 'wework', 'tremplin', 'horizon', 'espérer', 'être', 'relation', 'incubateur', 'premier', 'plan', 'france', 'entreprise', 'accompagner', 'banque', 'pouvoir', 'outre', 'être', 'accueillir', 'certain', 'centre', 'affaire', 'dune', 'nouvel', 'immeuble', 'fontenay-sous-bois', 'démarche', 'banque', 'reconnaître', 'creux', 'pouvoir', 'prendre', 'retard', 'thématique', 'développement', 'innovation', 'réseau', 'partenaire', 'client', 'tisser', 'prochaine', 'année', 'permettre', 'aussi', 'progresser', 'e.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models,corpora\n",
    "dictionary = corpora.Dictionary(tokenized_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "lsi_model = models.LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic #0: 0.007*\"entreprise\" + 0.005*\"service\" + 0.005*\"nouveau\" + 0.005*\"plus\" + 0.005*\"pouvoir\" + 0.004*\"client\" + 0.004*\"france\" + 0.004*\"permettre\" + 0.004*\"projet\" + 0.003*\"donnée\"\n",
      "Topic #1: 0.012*\"plus\" + 0.007*\"pouvoir\" + 0.006*\"entreprise\" + 0.005*\"faire\" + 0.005*\"aussi\" + 0.004*\"comme\" + 0.004*\"être\" + 0.004*\"grand\" + 0.004*\"start-up\" + 0.004*\"an\"\n",
      "Topic #2: 0.011*\"the\" + 0.008*\"plus\" + 0.007*\"of\" + 0.006*\"and\" + 0.005*\"to\" + 0.005*\"luxembourg\" + 0.004*\"in\" + 0.003*\"pouvoir\" + 0.003*\"an\" + 0.003*\"euro\"\n",
      "Topic #3: 0.009*\"projet\" + 0.008*\"entreprise\" + 0.006*\"plus\" + 0.006*\"espace\" + 0.006*\"pouvoir\" + 0.005*\"euro\" + 0.004*\"nouveau\" + 0.004*\"aussi\" + 0.003*\"travail\" + 0.003*\"start-up\"\n",
      "Topic #4: 0.007*\"plus\" + 0.006*\"entreprise\" + 0.004*\"pouvoir\" + 0.003*\"https\" + 0.003*\"start-up\" + 0.003*\"comme\" + 0.003*\"e=\" + 0.003*\"grand\" + 0.003*\"c=sfymryylsugfxnyao2svzg\" + 0.003*\"d=dwmgaq\"\n",
      "Topic #5: 0.007*\"france\" + 0.007*\"plus\" + 0.006*\"entreprise\" + 0.005*\"pouvoir\" + 0.004*\"pari\" + 0.004*\"innovation\" + 0.004*\"comme\" + 0.004*\"français\" + 0.004*\"faire\" + 0.003*\"aussi\"\n",
      "Topic #6: 0.011*\"start-up\" + 0.009*\"entreprise\" + 0.008*\"plus\" + 0.006*\"projet\" + 0.005*\"incubateur\" + 0.005*\"innovation\" + 0.004*\"an\" + 0.004*\"jeune\" + 0.004*\"entrepreneur\" + 0.004*\"grand\"\n",
      "Topic #7: 0.011*\"heure\" + 0.008*\"entreprise\" + 0.006*\"bordeaux\" + 0.004*\"plus\" + 0.004*\"an\" + 0.003*\"projet\" + 0.003*\"contact\" + 0.003*\"nouveau\" + 0.003*\"président\" + 0.003*\"pouvoir\"\n",
      "Topic #8: 0.008*\"entreprise\" + 0.005*\"plus\" + 0.005*\"aussi\" + 0.005*\"an\" + 0.004*\"projet\" + 0.004*\"faire\" + 0.003*\"comme\" + 0.003*\"pouvoir\" + 0.003*\"deux\" + 0.003*\"école\"\n",
      "Topic #9: 0.010*\"entreprise\" + 0.008*\"projet\" + 0.006*\"pouvoir\" + 0.006*\"plus\" + 0.005*\"pépinière\" + 0.005*\"an\" + 0.004*\"deux\" + 0.004*\"faire\" + 0.003*\"tout\" + 0.003*\"aussi\"\n",
      "====================\n",
      "LSI Model:\n",
      "Topic #0: 0.286*\"plus\" + 0.261*\"the\" + 0.194*\"entreprise\" + 0.168*\"pouvoir\" + 0.153*\"of\" + 0.140*\"an\" + 0.137*\"and\" + 0.127*\"projet\" + 0.119*\"to\" + 0.110*\"euro\"\n",
      "Topic #1: -0.524*\"the\" + -0.297*\"of\" + -0.246*\"and\" + -0.234*\"to\" + -0.175*\"luxembourg\" + -0.165*\"in\" + 0.159*\"projet\" + 0.154*\"entrepreneur\" + 0.134*\"bordeaux\" + 0.133*\"entreprise\"\n",
      "Topic #2: -0.316*\"entrepreneur\" + -0.289*\"date\" + -0.288*\"dotation\" + -0.270*\"profil\" + -0.267*\"limite\" + -0.261*\"dossier\" + -0.259*\"inscrire\" + -0.258*\"dépôt\" + -0.174*\"the\" + 0.166*\"plus\"\n",
      "Topic #3: -0.459*\"bordeaux\" + 0.145*\"faire\" + 0.143*\"pouvoir\" + -0.136*\"nouvelle-aquitaine\" + 0.119*\"start-up\" + -0.119*\"aquitaine\" + 0.116*\"comme\" + 0.113*\"france\" + -0.111*\"gironde\" + 0.111*\"plus\"\n",
      "Topic #4: -0.365*\"opération\" + -0.305*\"campus\" + -0.263*\"université\" + -0.190*\"euro\" + -0.179*\"million\" + -0.178*\"immobilier\" + -0.165*\"site\" + -0.163*\"état\" + -0.132*\"contrat\" + -0.128*\"établissement\"\n",
      "Topic #5: -0.400*\"euro\" + -0.350*\"million\" + 0.218*\"campus\" + 0.207*\"opération\" + 0.202*\"université\" + -0.196*\"entreprise\" + -0.157*\"résultat\" + -0.154*\"activité\" + -0.140*\"affaire\" + -0.139*\"chiffre\"\n",
      "Topic #6: -0.320*\"france\" + 0.285*\"start-up\" + -0.279*\"radio\" + -0.243*\"public\" + 0.222*\"recherche\" + 0.221*\"associé\" + 0.194*\"entreprise\" + 0.163*\"contacter\" + 0.151*\"an\" + -0.144*\"média\"\n",
      "Topic #7: 0.273*\"radio\" + 0.261*\"recherche\" + 0.253*\"associé\" + 0.244*\"france\" + 0.226*\"public\" + 0.198*\"contacter\" + 0.167*\"start-up\" + 0.149*\"service\" + 0.140*\"média\" + -0.135*\"an\"\n",
      "Topic #8: 0.323*\"the\" + 0.199*\"france\" + -0.183*\"marché\" + 0.170*\"entreprise\" + -0.168*\"plus\" + -0.135*\"luxembourg\" + -0.133*\"client\" + 0.120*\"of\" + 0.117*\"radio\" + -0.113*\"https\"\n",
      "Topic #9: 0.352*\"https\" + 0.336*\"e=\" + 0.336*\"//urldefense.proofpoint.com/v2/url\" + 0.336*\"d=dwmgaq\" + 0.336*\"c=sfymryylsugfxnyao2svzg\" + 0.336*\"r=9chkp3bakplifptles8oeribuqorq1cnygcyl5qe3rm\" + 0.156*\"heure\" + 0.149*\"entreprise\" + 0.122*\"m=xymsrsnoxkpcat84ordhmnwrikdkwtzhjvtrmf1itfg\" + -0.102*\"associé\"\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Model:\")\n",
    " \n",
    "for idx in range(10):\n",
    "    # Print the first 10 most representative topics\n",
    "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 10))\n",
    " \n",
    "print(\"=\" * 20)\n",
    " \n",
    "print(\"LSI Model:\")\n",
    " \n",
    "for idx in range(10):\n",
    "    # Print the first 10 most representative topics\n",
    "    print(\"Topic #%s:\" % idx, lsi_model.print_topic(idx, 10))\n",
    " \n",
    "print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
