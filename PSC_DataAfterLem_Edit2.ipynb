{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import nltk.data\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class JSONObject:\n",
    "     def __init__(self, d):\n",
    "         self.__dict__ = d\n",
    "\n",
    "with open(\"articles_Accuracy.json\", \"r\") as read_file:\n",
    "    data = read_file.read()\n",
    "    obj = json.loads(data,object_hook=JSONObject)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopworddic = set(stopwords.words('french'))\n",
    "article=['a','au','aux','un','une','le','la','les','de','des','ce','cet','cette','ces','son','sa','ses','leur','leurs','mon','ma','mes','ton','ta','tes','notre','notres','votre','votres']\n",
    "pronom=['je','tu','il','elle','nous','vous','ils','elles','on','y','en','se']\n",
    "coordination=['mais','ou','et','donc','or','ni','car']\n",
    "v=['aller','vais','vas','va','allez','allions','vont']\n",
    "stopworddic.update(set(article),set(pronom),set(coordination),set(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = FrenchLefffLemmatizer()\n",
    "def lemma(word):\n",
    "    a=lemmatizer.lemmatize(word,'all')\n",
    "    b=[x[1] for x in a]\n",
    "    if 'nc' in b:\n",
    "        return lemmatizer.lemmatize(word,'n')\n",
    "    if 'v' in b:\n",
    "        return lemmatizer.lemmatize(word,'v')\n",
    "    return lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "rawtokens=nltk.word_tokenize(obj[0].body_fr)\n",
    "metokens = [w.lower() for w in rawtokens if re.search('[a-zA-ZàâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]+',w)]\n",
    "latokens=[]\n",
    "for str in metokens:\n",
    "    if(re.search(r'\\w+\\'',str)):\n",
    "        str=re.sub(r'\\w+\\'', '', str) \n",
    "    latokens.append(str)\n",
    "tokens = [w for w in latokens if w not in stopworddic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worduselessdic=set(['plus','the','of','aussi','être','faire','comme','pouvoir','and','to','tout','in' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_data=[]\n",
    "for doc in obj :\n",
    "    if len(doc.body_fr)>2 :\n",
    "        text=doc.body_fr\n",
    "        text=nltk.word_tokenize(text)\n",
    "        text = [w.lower() for w in text if re.search('[a-zA-ZàâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]+',w)]\n",
    "        latokens=[]\n",
    "        for str in text:\n",
    "            if(re.search(r'\\w+\\'',str)):\n",
    "                str=re.sub(r'\\w+\\'', '', str) \n",
    "            latokens.append(str)\n",
    "        tokens = [w for w in latokens if w not in stopworddic]\n",
    "        text = [lemma(w) for w in tokens]\n",
    "        text = [w for w in text if w not in worduselessdic]\n",
    "        tokenized_data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['groupe', 'défense', 'vouloir', 'accompagner', 'jeune', 'pousse', 'français', 'haut', 'potentiel', 'ici', 'banque', 'compléter', 'offre', 'travailler', 'insérer', 'écosystème', 'développement', 'entreprise', 'société', 'général', 'mettre', 'quête', 'nouveau', 'pépite', 'banque', 'défense', 'servir', 'déjà', 'start-up', 'dont', 'juger', 'particulièrement', 'prometteuses', 'annoncer', 'mardi', 'souhaiter', 'séduire', 'supplémentaires', 'horizon', 'ensemble', 'territoire', 'jargon', 'banque', 'pépite', 'entreprise', 'déjà', 'réussir', 'première', 'levée', 'fond', 'moins', 'euro', 'accompagner', 'incubateur', 'phare', 'fond', 'capital-risque', 'créer', 'idéalement', 'entrepreneur', 'coup', 'essai', 'agir', 'entreprise', 'déjà', 'suivre', 'banque', 'doit', 'encore', 'grandir', 'recrutement', 'externe', 'parvenir', 'banque', 'peaufiner', 'arsenal', 'signer', 'lundi', 'prochain', 'partenariat', 'bpifrance', 'vue', 'notamment', 'dialoguer', 'conseiller', 'réseau', 'bancaire', 'chargé', 'affaire', 'innovation', 'établissement', 'public', 'seul', 'bnp', 'paribas', 'heure', 'passé', 'tel', 'accord', 'bpifrance', 'deuxième', 'nouveauté', 'concerner', 'ensemble', 'jeune', 'pousse', 'tech', 'bénéficier', 'offre', 'dédier', 'baptisé', 'welcome', 'pack', 'startup', 'dernier', 'comprendre', 'notamment', 'service', 'banque', 'mobile', 'moyen', 'paiement', 'encore', 'bilan', 'patrimonial', 'industrialiser', 'pratique', 'démarche', 'groupe', 'bancaire', 'loin', 'simple', 'offre', 'commercial', 'viser', 'désormais', 'industrialiser', 'pratique', 'déjà', 'place', 'depuis', 'plusieurs', 'année', 'animation', 'clientèle', 'si', 'particulière', 'compléter', 'entériner', 'dispositif', 'conseiller', 'référent', 'start-up', 'selon', 'ville', 'nombre', 'créateur', 'suivre', 'rôle', 'occuper', 'plein', 'temps', 'façon', 'partielle', 'conseiller', 'clientèle', 'classique', 'rôle', 'notamment', 'orienter', 'client', 'travers', 'ensemble', 'service', 'apporter', 'groupe', 'enfin', 'huit', 'ambassadeur', 'chargé', 'identifier', 'connaître', 'direction', 'général', 'entreprise', 'portefeuille', 'pointe', 'prometteuses', 'travail', 'animation', 'interne', 'partage', 'client', 'marque', 'fabrique', 'banque', 'logo', 'rouge', 'noir', 'mener', 'passé', 'type', 'démarche', 'développer', 'service', 'banque', 'priver', 'travail', 'réseau', 'banque', 'mener', 'externe', 'devenir', 'partenaire', 'bancaire', 'vingtaine', 'incubateur', 'dont', 'station', 'f', 'wework', 'tremplin', 'horizon', 'espérer', 'relation', 'incubateur', 'premier', 'plan', 'france', 'entreprise', 'accompagner', 'banque', 'outre', 'accueillir', 'certain', 'centre', 'affaire', 'dune', 'nouvel', 'immeuble', 'fontenay-sous-bois', 'démarche', 'banque', 'reconnaître', 'creux', 'prendre', 'retard', 'thématique', 'développement', 'innovation', 'réseau', 'partenaire', 'client', 'tisser', 'prochaine', 'année', 'permettre', 'progresser', 'e.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Surface\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import models,corpora\n",
    "dictionary = corpora.Dictionary(tokenized_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "lsi_model = models.LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic #0: 0.006*\"entreprise\" + 0.004*\"nouveau\" + 0.004*\"projet\" + 0.004*\"deux\" + 0.004*\"espace\" + 0.003*\"an\" + 0.003*\"euro\" + 0.003*\"site\" + 0.003*\"grand\" + 0.003*\"bâtiment\"\n",
      "Topic #1: 0.006*\"entreprise\" + 0.005*\"projet\" + 0.004*\"nouveau\" + 0.004*\"euro\" + 0.003*\"commune\" + 0.003*\"ville\" + 0.003*\"an\" + 0.003*\"dernier\" + 0.003*\"pari\" + 0.003*\"développement\"\n",
      "Topic #2: 0.005*\"entreprise\" + 0.005*\"start-up\" + 0.004*\"nouveau\" + 0.004*\"an\" + 0.004*\"groupe\" + 0.004*\"service\" + 0.004*\"projet\" + 0.004*\"pari\" + 0.003*\"permettre\" + 0.003*\"client\"\n",
      "Topic #3: 0.006*\"entreprise\" + 0.005*\"an\" + 0.004*\"france\" + 0.004*\"projet\" + 0.004*\"école\" + 0.004*\"jeune\" + 0.004*\"fait\" + 0.003*\"start-up\" + 0.003*\"nouveau\" + 0.003*\"deux\"\n",
      "Topic #4: 0.006*\"luxembourg\" + 0.005*\"entreprise\" + 0.003*\"heure\" + 0.003*\"contact\" + 0.003*\"européen\" + 0.003*\"ministre\" + 0.003*\"is\" + 0.003*\"for\" + 0.003*\"nouveau\" + 0.003*\"ainsi\"\n",
      "Topic #5: 0.009*\"entreprise\" + 0.007*\"heure\" + 0.007*\"bordeaux\" + 0.004*\"an\" + 0.004*\"nouveau\" + 0.003*\"projet\" + 0.003*\"innovation\" + 0.003*\"président\" + 0.003*\"réseau\" + 0.003*\"deux\"\n",
      "Topic #6: 0.011*\"entreprise\" + 0.006*\"start-up\" + 0.005*\"projet\" + 0.005*\"an\" + 0.004*\"grand\" + 0.004*\"france\" + 0.004*\"innovation\" + 0.004*\"incubateur\" + 0.003*\"euro\" + 0.003*\"fait\"\n",
      "Topic #7: 0.006*\"nouveau\" + 0.006*\"start-up\" + 0.004*\"million\" + 0.004*\"fond\" + 0.004*\"euro\" + 0.004*\"marché\" + 0.004*\"permettre\" + 0.003*\"service\" + 0.003*\"france\" + 0.003*\"innovation\"\n",
      "Topic #8: 0.011*\"entreprise\" + 0.005*\"projet\" + 0.005*\"grand\" + 0.005*\"nouveau\" + 0.004*\"an\" + 0.003*\"bien\" + 0.003*\"pépinière\" + 0.003*\"travail\" + 0.003*\"deux\" + 0.003*\"fait\"\n",
      "Topic #9: 0.012*\"projet\" + 0.011*\"entreprise\" + 0.008*\"start-up\" + 0.007*\"entrepreneur\" + 0.004*\"an\" + 0.004*\"nouveau\" + 0.004*\"innovation\" + 0.004*\"dossier\" + 0.004*\"incubateur\" + 0.004*\"développement\"\n",
      "====================\n",
      "LSI Model:\n",
      "Topic #0: 0.238*\"entreprise\" + 0.175*\"nouveau\" + 0.169*\"an\" + 0.167*\"projet\" + 0.137*\"euro\" + 0.121*\"service\" + 0.108*\"bordeaux\" + 0.107*\"grand\" + 0.106*\"année\" + 0.105*\"innovation\"\n",
      "Topic #1: -0.347*\"entrepreneur\" + -0.301*\"dotation\" + -0.298*\"date\" + -0.278*\"profil\" + -0.276*\"limite\" + -0.272*\"dossier\" + -0.268*\"dépôt\" + -0.267*\"inscrire\" + -0.191*\"projet\" + -0.115*\"prix\"\n",
      "Topic #2: -0.481*\"bordeaux\" + 0.193*\"luxembourg\" + -0.142*\"nouvelle-aquitaine\" + -0.122*\"aquitaine\" + -0.115*\"gironde\" + 0.107*\"européen\" + -0.096*\"passager\" + -0.095*\"heure\" + -0.093*\"m€\" + -0.093*\"réseau\"\n",
      "Topic #3: 0.269*\"luxembourg\" + -0.213*\"france\" + 0.189*\"euro\" + -0.176*\"start-up\" + 0.144*\"bordeaux\" + 0.114*\"is\" + -0.111*\"français\" + 0.108*\"for\" + -0.106*\"public\" + -0.106*\"jeune\"\n",
      "Topic #4: -0.426*\"opération\" + -0.378*\"campus\" + -0.331*\"université\" + -0.210*\"site\" + -0.184*\"état\" + -0.174*\"projet\" + -0.148*\"établissement\" + -0.145*\"contrat\" + 0.133*\"entreprise\" + -0.132*\"immobilier\"\n",
      "Topic #5: 0.418*\"euro\" + 0.398*\"million\" + 0.182*\"entreprise\" + 0.176*\"résultat\" + -0.167*\"luxembourg\" + 0.158*\"activité\" + 0.157*\"chiffre\" + 0.149*\"opérationnel\" + 0.145*\"affaire\" + 0.141*\"immobilier\"\n",
      "Topic #6: -0.397*\"france\" + -0.337*\"radio\" + -0.297*\"public\" + 0.235*\"start-up\" + 0.184*\"associé\" + 0.176*\"recherche\" + -0.175*\"média\" + 0.171*\"entreprise\" + 0.153*\"an\" + -0.142*\"nouveau\"\n",
      "Topic #7: -0.298*\"associé\" + -0.293*\"recherche\" + -0.233*\"contacter\" + -0.189*\"radio\" + -0.186*\"start-up\" + -0.158*\"service\" + 0.155*\"an\" + -0.149*\"public\" + -0.119*\"france\" + -0.115*\"e\"\n",
      "Topic #8: -0.376*\"https\" + -0.357*\"//urldefense.proofpoint.com/v2/url\" + -0.357*\"d=dwmgaq\" + -0.357*\"r=9chkp3bakplifptles8oeribuqorq1cnygcyl5qe3rm\" + -0.357*\"e=\" + -0.357*\"c=sfymryylsugfxnyao2svzg\" + -0.129*\"m=xymsrsnoxkpcat84ordhmnwrikdkwtzhjvtrmf1itfg\" + -0.126*\"innovation\" + 0.105*\"an\" + -0.099*\"heure\"\n",
      "Topic #9: 0.608*\"entreprise\" + -0.186*\"français\" + -0.186*\"start-up\" + 0.174*\"projet\" + -0.146*\"afrique\" + -0.128*\"associé\" + -0.127*\"euro\" + -0.124*\"france\" + 0.119*\"pépinière\" + -0.112*\"africain\"\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Model:\")\n",
    " \n",
    "for idx in range(10):\n",
    "    # Print the first 10 most representative topics\n",
    "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 10))\n",
    " \n",
    "print(\"=\" * 20)\n",
    " \n",
    "print(\"LSI Model:\")\n",
    " \n",
    "for idx in range(10):\n",
    "    # Print the first 10 most representative topics\n",
    "    print(\"Topic #%s:\" % idx, lsi_model.print_topic(idx, 10))\n",
    " \n",
    "print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
